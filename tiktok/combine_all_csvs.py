#!/usr/bin/env python3
"""
åˆå¹¶æ‰€æœ‰TikTokæ•°æ®é›†çš„CSVæ–‡ä»¶å¹¶å»é‡
"""

import os

import pandas as pd

# å®šä¹‰æ‰€æœ‰æ•°æ®é›†
DATASETS = {
    "Bangladesh Flood": {
        "csv_path": "tiktok/bangladesh_flood/csvs/tiktok_posts_20240801_to_20241031.csv",
        "video_dir": "tiktok/bangladesh_flood/videos",
        "event": "Bangladesh Flood",
    },
    "Assam Flood": {
        "csv_path": "tiktok/assam_flood/csvs/filtered_assam_flood_posts_20240501_20241120_with_local_paths.csv",
        "video_dir": "tiktok/assam_flood/videos",
        "event": "Assam Flood",
    },
    "Kerala Flood": {
        "csv_path": "tiktok/kerala_flood/csvs/filtered_kerala_flood_posts_20240715_20241101_with_local_paths.csv",
        "video_dir": "tiktok/kerala_flood/videos",
        "event": "Kerala Flood",
    },
    "Pakistan Flood": {
        "csv_path": "tiktok/pakistan_flood/csvs/filtered_pakistan_flood_posts_20220601_20230101_with_local_paths.csv",
        "video_dir": "tiktok/pakistan_flood/videos",
        "event": "Pakistan Flood",
    },
    "South Asia Flood": {
        "csv_path": "tiktok/south_asia_flood/csvs/filtered_south_asia_flood_posts_with_local_paths.csv",
        "video_dir": "tiktok/south_asia_flood/videos",
        "event": "South Asia Flood",
    },
}


def load_and_standardize_csv(csv_path, event_name, video_dir):
    """åŠ è½½CSVæ–‡ä»¶å¹¶æ ‡å‡†åŒ–åˆ—"""
    print(f"åŠ è½½ {event_name}: {csv_path}")

    if not os.path.exists(csv_path):
        print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
        return None

    try:
        # è¯»å–CSVæ—¶å°†idåˆ—ä½œä¸ºå­—ç¬¦ä¸²å¤„ç†
        df = pd.read_csv(csv_path, dtype={"id": str})

        # æ·»åŠ äº‹ä»¶æ ‡è¯†å’Œæœ¬åœ°è§†é¢‘è·¯å¾„
        df["event"] = event_name
        df["video_local_path"] = df["id"].apply(lambda x: f"{video_dir}/tiktok_{x}.mp4")

        print(f"âœ“ æˆåŠŸåŠ è½½ {len(df)} æ¡è®°å½•")
        return df

    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")
        return None


def combine_csvs():
    """åˆå¹¶æ‰€æœ‰CSVæ–‡ä»¶"""
    print("ğŸš€ å¼€å§‹åˆå¹¶TikTokæ•°æ®é›†...\n")

    all_dataframes = []
    stats = {}

    # åŠ è½½æ‰€æœ‰æ•°æ®é›†
    for dataset_name, dataset_info in DATASETS.items():
        df = load_and_standardize_csv(
            dataset_info["csv_path"], dataset_info["event"], dataset_info["video_dir"]
        )

        if df is not None:
            all_dataframes.append(df)
            stats[dataset_name] = len(df)
        else:
            stats[dataset_name] = 0

        print()

    if not all_dataframes:
        print("âŒ æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ•°æ®é›†")
        return

    # åˆå¹¶æ‰€æœ‰æ•°æ®
    print("ğŸ”„ åˆå¹¶æ•°æ®...")
    combined_df = pd.concat(all_dataframes, ignore_index=True)
    print(f"âœ“ åˆå¹¶å®Œæˆï¼Œæ€»è®¡ {len(combined_df)} æ¡è®°å½•")

    # å»é‡ï¼ˆåŸºäºidåˆ—ï¼‰
    print("ğŸ”„ å»é™¤é‡å¤è®°å½•...")
    original_count = len(combined_df)
    combined_df = combined_df.drop_duplicates(subset=["id"], keep="first")
    deduplicated_count = len(combined_df)
    removed_duplicates = original_count - deduplicated_count

    print(f"âœ“ å»é‡å®Œæˆï¼Œç§»é™¤äº† {removed_duplicates} æ¡é‡å¤è®°å½•")
    print(f"âœ“ æœ€ç»ˆæ•°æ®é›†åŒ…å« {deduplicated_count} æ¡å”¯ä¸€è®°å½•")

    # æŒ‰ä¸Šä¼ æ—¶é—´æ’åº
    if "uploaded_at" in combined_df.columns:
        print("ğŸ”„ æŒ‰ä¸Šä¼ æ—¶é—´æ’åº...")
        combined_df = combined_df.sort_values("uploaded_at", ascending=False)
        print("âœ“ æ’åºå®Œæˆ")

    # ä¿å­˜åˆå¹¶åçš„CSV
    output_path = "tiktok/combined_all_floods.csv"
    print(f"ğŸ’¾ ä¿å­˜åˆ° {output_path}...")
    combined_df.to_csv(output_path, index=False)
    print("âœ“ ä¿å­˜å®Œæˆ")

    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 60)
    print("ğŸ“Š æ•°æ®é›†ç»Ÿè®¡")
    print("=" * 60)

    for dataset_name, count in stats.items():
        print(f"{dataset_name:20s}: {count:4d} æ¡è®°å½•")

    print(f"{'':20s}   ----")
    print(f"{'åŸå§‹æ€»è®¡':20s}: {original_count:4d} æ¡è®°å½•")
    print(f"{'å»é‡åæ€»è®¡':20s}: {deduplicated_count:4d} æ¡è®°å½•")
    print(f"{'é‡å¤è®°å½•':20s}: {removed_duplicates:4d} æ¡è®°å½•")

    # æŒ‰äº‹ä»¶ç»Ÿè®¡å»é‡åçš„æ•°æ®
    print("\nğŸ“ˆ å»é‡åæŒ‰äº‹ä»¶ç»Ÿè®¡:")
    event_stats = combined_df["event"].value_counts().sort_index()
    for event, count in event_stats.items():
        print(f"{event:20s}: {count:4d} æ¡è®°å½•")

    print(f"\nâœ¨ åˆå¹¶å®Œæˆï¼è¾“å‡ºæ–‡ä»¶: {output_path}")

    return output_path, stats, combined_df


if __name__ == "__main__":
    combine_csvs()
