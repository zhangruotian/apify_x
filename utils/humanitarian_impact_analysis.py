#!/usr/bin/env python3
"""
ä½¿ç”¨ Ollama Qwen VLM æ¨¡å‹å¯¹ TikTok/Twitter æ•°æ®è¿›è¡Œäººé“ä¸»ä¹‰å½±å“åˆ†æ
Humanitarian Impact Analysis for Flood-Related Social Media Posts
"""

import json
import os
import re
import base64
import pandas as pd
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
import asyncio
import aiohttp
from io import BytesIO
from PIL import Image
import random


class HumanitarianImpactAnalyzer:
    """ä½¿ç”¨ Ollama VLM è¿›è¡Œäººé“ä¸»ä¹‰å½±å“åˆ†æ"""
    
    def __init__(self, base_url: str = "http://127.0.0.1:11434", model: str = "qwen3-vl:32b-instruct"):
        self.base_url = base_url.rstrip('/')
        self.model = model
        self._image_cache = {}
        self._cache_max_size = 1000
        
        # ç³»ç»Ÿæç¤ºè¯
        self.system_prompt = """You are a conservative, evidence-driven humanitarian VLM for analyzing flood-related social media posts.

STRICT RULES
- Use TITLE TEXT and IMAGES (key frames).
- A label that requires visual cues may be TRUE only if the images clearly show those cues. Do NOT guess from common sense.
- HARD EVIDENCE POLICY (visual cues required unless noted):
  * infrastructure_access/damage_signs: flooded roads/bridges/houses, blocked vehicles, closed school/clinic signs, etc. Text alone is insufficient.
  * water_food_insecurity: do NOT infer from common sense; only mark loss_types.water_food_insecurity=true if images show distribution/containers/queues OR explicit on-image text that proves shortage. Plain caption is insufficient.
  * education_disruption: school building + closure cues (signs, closed gate, students turned away). Text alone insufficient.
  * displacement: shelters, group sleeping on floors, evacuation boats with belongings. Text alone insufficient.
  * caregiving_burden: visible caregiving actions (carrying child/elderly, wheelchair assistance). Text alone insufficient.
  * psychosocial_distress: do NOT infer from faces; set false unless text explicitly states psychological suffering AND images support the context.
  * urgency_score_0_5 > 0 only when visual danger cues exist (deep water around people/houses, blocked roads, structural damage, active rescue).
- PRIVACY: no identity inference. Demographics are visibility flags only (true only if clearly visible in images).

SCORING
- Precision over recall: false positives are worse than false negatives.
- If uncertain, set present=false (confidence<=0.4).

OUTPUT
- Return STRICT JSON ONLY, exactly matching the schema in the user message. No extra keys, no prose.
- Keep "evidence" concise (â‰¤ 200 characters)."""
        
    def _compress_image(self, image_path: Path, max_short_side: int = 512, quality: int = 85) -> bytes:
        """å‹ç¼©å›¾ç‰‡ï¼šçŸ­è¾¹â‰¤512ï¼ŒJPEG quality=85ï¼Œoptimize=True"""
        try:
            with Image.open(image_path) as img:
                if img.mode in ('RGBA', 'LA', 'P'):
                    background = Image.new('RGB', img.size, (255, 255, 255))
                    if img.mode == 'P':
                        img = img.convert('RGBA')
                    background.paste(img, mask=img.split()[-1] if img.mode == 'RGBA' else None)
                    img = background
                elif img.mode != 'RGB':
                    img = img.convert('RGB')
                
                width, height = img.size
                if min(width, height) > max_short_side:
                    ratio = max_short_side / min(width, height)
                    new_width = int(width * ratio)
                    new_height = int(height * ratio)
                    img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
                
                output = BytesIO()
                img.save(output, format='JPEG', quality=quality, optimize=True)
                return output.getvalue()
        except Exception as e:
            print(f"âš ï¸  Image compression failed for {image_path}: {e}, using original")
            with open(image_path, "rb") as f:
                return f.read()
    
    def encode_image(self, image_path: str, use_cache: bool = True) -> str:
        """å°†å›¾åƒæ–‡ä»¶ç¼–ç ä¸º base64ï¼ˆå¸¦å‹ç¼©å’Œç¼“å­˜ï¼‰"""
        image_path_str = str(image_path)
        image_path = Path(image_path)
        
        if use_cache and image_path_str in self._image_cache:
            return self._image_cache[image_path_str]
        
        if not image_path.exists():
            raise FileNotFoundError(f"Image file not found: {image_path}")
        
        image_data = self._compress_image(image_path)
        # è¿”å›çº¯ base64ï¼ˆOllama 0.12.x æœŸæœ› raw base64ï¼Œè€Œä¸æ˜¯ data URIï¼‰
        encoded = base64.b64encode(image_data).decode('utf-8')
        
        if use_cache:
            if len(self._image_cache) >= self._cache_max_size:
                oldest_key = next(iter(self._image_cache))
                del self._image_cache[oldest_key]
            self._image_cache[image_path_str] = encoded
        
        return encoded
    
    def _build_prompt_tiktok(
        self,
        title: str,
        hashtags: str,
        transcription: str,
        image_paths: List[str],
        project_root: Optional[Path] = None
    ) -> Tuple[str, List[str]]:
        """æ„å»º TikTok æ•°æ®çš„ prompt"""
        # å‡†å¤‡æ–‡æœ¬å†…å®¹
        title_text = ""
        if title and str(title).strip() and str(title).strip().lower() != 'nan':
            title_text = str(title).strip()
        
        # åˆå¹¶ hashtags åˆ°æ–‡æœ¬ä¸­
        post_text_concat = title_text
        if hashtags and str(hashtags).strip() and str(hashtags).strip().lower() != 'nan':
            hashtags_text = str(hashtags).strip()
            if post_text_concat:
                post_text_concat += f" #{hashtags_text.replace(',', ' #')}"
            else:
                post_text_concat = f"#{hashtags_text.replace(',', ' #')}"
        
        # åŠ è½½å›¾åƒï¼ˆä½¿ç”¨å…¨éƒ¨3å¼ ï¼Œå¦‚æœå¯ç”¨ï¼‰
        images_base64 = []
        for img_path in image_paths[:3]:  # é™åˆ¶æœ€å¤š3å¼ 
            try:
                if project_root:
                    full_path = project_root / img_path
                else:
                    full_path = Path(img_path)
                
                if full_path.exists():
                    img_b64 = self.encode_image(str(full_path))
                    images_base64.append(img_b64)
            except Exception:
                continue
        
        if not images_base64 and not post_text_concat:
            raise ValueError("No images or text available")
        
        # æ„å»ºç”¨æˆ·æç¤ºè¯
        user_prompt = f"""Task: Visual-first extraction of NON-ECONOMIC flood impact signals for ONE post.

Apply the HARD EVIDENCE policy. Use ONLY TITLE/TEXT and the attached IMAGES (key frames). 

Demography flags must come from IMAGES ONLY. If the group is not clearly visible, set the flag to false.

POST CONTEXT

TITLE:
<<<{title_text if title_text else 'N/A'}>>>

TEXT (caption/hashtags/OCR merged):
<<<{post_text_concat if post_text_concat else 'N/A'}>>>

{len(images_base64)} image(s) attached via the API call.

Return EXACTLY this JSON (and nothing else):
{{
  "loss_types": {{
    "displacement":              {{"present": false, "confidence": 0.0}},
    "education_disruption":      {{"present": false, "confidence": 0.0}},
    "health_trauma":             {{"present": false, "confidence": 0.0}},
    "social_ties_loss":          {{"present": false, "confidence": 0.0}},
    "cultural_ritual_disruption":{{"present": false, "confidence": 0.0}},
    "caregiving_burden":         {{"present": false, "confidence": 0.0}},
    "water_food_insecurity":     {{"present": false, "confidence": 0.0}},
    "infrastructure_access":     {{"present": false, "confidence": 0.0}},
    "psychosocial_distress":     {{"present": false, "confidence": 0.0}}
  }},
  "urgency_score_0_5": 0,
  "visual_cues": {{
    "water_depth_bin": "unknown",
    "crowd_size_bin": "unknown",
    "relief_visible": false,
    "relief_actor_type": "none",
    "damage_signs": ["none"]
  }},
  "demography_presence": {{
    "children": false,
    "elderly": false,
    "pregnant": false,
    "disabled_aid": false,
    "male": false,
    "female": false
  }},
  "scene_type": {{
    "aerial": false,
    "ground_outdoor": false,
    "indoor": false
  }},
  "context_area": ["unknown"],
  "sentiment": [
    {{"label":"fear","present":false,"confidence":0.0}},
    {{"label":"hopelessness","present":false,"confidence":0.0}},
    {{"label":"grief","present":false,"confidence":0.0}},
    {{"label":"anger","present":false,"confidence":0.0}},
    {{"label":"resilience","present":false,"confidence":0.0}},
    {{"label":"neutral","present":false,"confidence":0.0}},
    {{"label":"mixed","present":false,"confidence":0.0}}
  ],
  "recovery": {{
    "recovery_signals": false,
    "evidence": ""
  }}
}}

FIELD DEFINITIONS:
- water_depth_bin: one of {{"none","ankle","knee","waist","vehicle_height","indoor_flood","unknown"}}
- crowd_size_bin: one of {{"1","2-5","6-20",">20","unknown"}}
- relief_actor_type: one of {{"ngo","government","community","unknown","none"}}
- damage_signs: choose any of {{"road_blocked","house_inundated","bridge_damage","school_closed_sign","clinic_closed_sign","power_outage_sign","other","none"}}
- context_area: choose any subset of {{"settlement","farmland","roadway","riverbank","school_or_health_facility","mixed","unknown"}}
- confidence values: 0.0 to 1.0
- urgency_score_0_5: integer from 0 to 5"""
        
        return user_prompt, images_base64
    
    def _build_prompt_twitter(
        self,
        text: str,
        image_paths: List[str],
        project_root: Optional[Path] = None
    ) -> Tuple[str, List[str]]:
        """æ„å»º Twitter æ•°æ®çš„ prompt"""
        # å‡†å¤‡æ–‡æœ¬å†…å®¹
        tweet_text = ""
        if text and str(text).strip() and str(text).strip().lower() != 'nan':
            tweet_text = str(text).strip()
        
        # åŠ è½½å›¾åƒï¼ˆæœ€å¤š3å¼ ï¼‰
        images_base64 = []
        for img_path in image_paths[:3]:
            try:
                if project_root:
                    full_path = project_root / img_path
                else:
                    full_path = Path(img_path)
                
                if full_path.exists():
                    img_b64 = self.encode_image(str(full_path))
                    images_base64.append(img_b64)
            except Exception:
                continue
        
        if not images_base64 and not tweet_text:
            raise ValueError("No images or text available")
        
        # æ„å»ºç”¨æˆ·æç¤ºè¯ï¼ˆTwitter ç‰ˆæœ¬ï¼šæ—  transcriptionï¼‰
        user_prompt = f"""Task: Visual-first extraction of NON-ECONOMIC flood impact signals for ONE post.

Apply the HARD EVIDENCE policy. Use ONLY TITLE/TEXT and the attached IMAGES (key frames).

Demography flags must come from IMAGES ONLY. If the group is not clearly visible, set the flag to false.

POST CONTEXT

TEXT (tweet content):
<<<{tweet_text if tweet_text else 'N/A'}>>>

{len(images_base64)} image(s) attached via the API call.

Return EXACTLY this JSON (and nothing else):
{{
  "loss_types": {{
    "displacement":              {{"present": false, "confidence": 0.0}},
    "education_disruption":      {{"present": false, "confidence": 0.0}},
    "health_trauma":             {{"present": false, "confidence": 0.0}},
    "social_ties_loss":          {{"present": false, "confidence": 0.0}},
    "cultural_ritual_disruption":{{"present": false, "confidence": 0.0}},
    "caregiving_burden":         {{"present": false, "confidence": 0.0}},
    "water_food_insecurity":     {{"present": false, "confidence": 0.0}},
    "infrastructure_access":     {{"present": false, "confidence": 0.0}},
    "psychosocial_distress":     {{"present": false, "confidence": 0.0}}
  }},
  "urgency_score_0_5": 0,
  "visual_cues": {{
    "water_depth_bin": "unknown",
    "crowd_size_bin": "unknown",
    "relief_visible": false,
    "relief_actor_type": "none",
    "damage_signs": ["none"]
  }},
  "demography_presence": {{
    "children": false,
    "elderly": false,
    "pregnant": false,
    "disabled_aid": false,
    "male": false,
    "female": false
  }},
  "scene_type": {{
    "aerial": false,
    "ground_outdoor": false,
    "indoor": false
  }},
  "context_area": ["unknown"],
  "sentiment": [
    {{"label":"fear","present":false,"confidence":0.0}},
    {{"label":"hopelessness","present":false,"confidence":0.0}},
    {{"label":"grief","present":false,"confidence":0.0}},
    {{"label":"anger","present":false,"confidence":0.0}},
    {{"label":"resilience","present":false,"confidence":0.0}},
    {{"label":"neutral","present":false,"confidence":0.0}},
    {{"label":"mixed","present":false,"confidence":0.0}}
  ],
  "recovery": {{
    "recovery_signals": false,
    "evidence": ""
  }}
}}

FIELD DEFINITIONS:
- water_depth_bin: one of {{"none","ankle","knee","waist","vehicle_height","indoor_flood","unknown"}}
- crowd_size_bin: one of {{"1","2-5","6-20",">20","unknown"}}
- relief_actor_type: one of {{"ngo","government","community","unknown","none"}}
- damage_signs: choose any of {{"road_blocked","house_inundated","bridge_damage","school_closed_sign","clinic_closed_sign","power_outage_sign","other","none"}}
- context_area: choose any subset of {{"settlement","farmland","roadway","riverbank","school_or_health_facility","mixed","unknown"}}
- confidence values: 0.0 to 1.0
- urgency_score_0_5: integer from 0 to 5"""
        
        return user_prompt, images_base64
    
    def _parse_response(self, content: str) -> Dict[str, Any]:
        """è§£ææ¨¡å‹å“åº”ï¼Œæå– JSON"""
        # å°è¯•æå– JSON å¯¹è±¡
        json_match = re.search(r'\{.*\}', content, re.DOTALL)
        if json_match:
            try:
                json_str = json_match.group(0)
                parsed = json.loads(json_str)
                # éªŒè¯å¿…è¦çš„å­—æ®µ
                if "loss_types" in parsed and "urgency_score_0_5" in parsed:
                    return parsed
            except json.JSONDecodeError:
                pass
        
        # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤ç»“æ„
        print(f"âš ï¸  Failed to parse response, using default values. Response: {content[:200]}")
        return self._get_default_response()
    
    def _get_default_response(self) -> Dict[str, Any]:
        """è¿”å›é»˜è®¤çš„ç©ºå“åº”ç»“æ„"""
        return {
            "loss_types": {
                "displacement": {"present": False, "confidence": 0.0},
                "education_disruption": {"present": False, "confidence": 0.0},
                "health_trauma": {"present": False, "confidence": 0.0},
                "social_ties_loss": {"present": False, "confidence": 0.0},
                "cultural_ritual_disruption": {"present": False, "confidence": 0.0},
                "caregiving_burden": {"present": False, "confidence": 0.0},
                "water_food_insecurity": {"present": False, "confidence": 0.0},
                "infrastructure_access": {"present": False, "confidence": 0.0},
                "psychosocial_distress": {"present": False, "confidence": 0.0}
            },
            "urgency_score_0_5": 0,
            "visual_cues": {
                "water_depth_bin": "unknown",
                "crowd_size_bin": "unknown",
                "relief_visible": False,
                "relief_actor_type": "none",
                "damage_signs": ["none"]
            },
            "demography_presence": {
                "children": False,
                "elderly": False,
                "pregnant": False,
                "disabled_aid": False,
                "male": False,
                "female": False
            },
            "scene_type": {
                "aerial": False,
                "ground_outdoor": False,
                "indoor": False
            },
            "context_area": ["unknown"],
            "sentiment": [
                {"label": "fear", "present": False, "confidence": 0.0},
                {"label": "hopelessness", "present": False, "confidence": 0.0},
                {"label": "grief", "present": False, "confidence": 0.0},
                {"label": "anger", "present": False, "confidence": 0.0},
                {"label": "resilience", "present": False, "confidence": 0.0},
                {"label": "neutral", "present": False, "confidence": 0.0},
                {"label": "mixed", "present": False, "confidence": 0.0}
            ],
            "recovery": {
                "recovery_signals": False,
                "evidence": ""
            }
        }

    def _make_payload(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æ„å»º Ollama è¯·æ±‚ payloadï¼ˆå¤ç”¨é…ç½®é¿å…é‡å¤ä»£ç ï¼‰"""
        return {
            "model": self.model,
            "messages": messages,
            "stream": False,
            "options": {
                "num_gpu": 999,
                "num_ctx": 2048,
                "num_batch": 128,
                "format": "json",
                "temperature": 0.1, 
                "use_mmap": False
            },
            "keep_alive": "4h"
        }

    async def warm_up(self, session: Optional[aiohttp.ClientSession] = None) -> None:
        """é¢„çƒ­æ¨¡å‹ï¼Œé™ä½é¦–ä¸ªè¯·æ±‚çš„å¯åŠ¨å»¶è¿Ÿ"""
        warm_messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": "Warm up and respond with OK."}
        ]
        payload = self._make_payload(warm_messages)
        try:
            if session is None:
                async with aiohttp.ClientSession() as temp_session:
                    async with temp_session.post(
                        f"{self.base_url}/api/chat",
                        json=payload,
                        headers={"Content-Type": "application/json"},
                        timeout=aiohttp.ClientTimeout(total=120, connect=30)
                    ) as response:
                        response.raise_for_status()
            else:
                async with session.post(
                    f"{self.base_url}/api/chat",
                    json=payload,
                    headers={"Content-Type": "application/json"},
                    timeout=aiohttp.ClientTimeout(total=120, connect=30)
                ) as response:
                    response.raise_for_status()
        except Exception as warm_err:
            print(f"âš ï¸  Warm-up request failed (ignored): {warm_err}")
    
    async def _send_analysis_request(
        self,
        user_prompt: str,
        images_base64: List[str],
        session: Optional[aiohttp.ClientSession] = None,
        max_retries: int = 5
    ) -> Dict[str, Any]:
        """å‘é€åˆ†æè¯·æ±‚ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        # æ„å»ºæ¶ˆæ¯
        messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": user_prompt, "images": images_base64}
        ]
        
        payload = self._make_payload(messages)
        
        for attempt in range(max_retries):
            try:
                if session is None:
                    async with aiohttp.ClientSession() as temp_session:
                        async with temp_session.post(
                            f"{self.base_url}/api/chat",
                            json=payload,
                            headers={"Content-Type": "application/json"},
                            timeout=aiohttp.ClientTimeout(total=600, connect=30)
                        ) as response:
                            response.raise_for_status()
                            result = await response.json()
                            content = result.get("message", {}).get("content", "")
                            return self._parse_response(content)
                else:
                    async with session.post(
                        f"{self.base_url}/api/chat",
                        json=payload,
                        headers={"Content-Type": "application/json"},
                        timeout=aiohttp.ClientTimeout(total=600, connect=30)
                    ) as response:
                        response.raise_for_status()
                        result = await response.json()
                        content = result.get("message", {}).get("content", "")
                        return self._parse_response(content)
                        
            except (aiohttp.ClientError, ConnectionError, BrokenPipeError, OSError, 
                    aiohttp.ClientConnectorError, aiohttp.ServerDisconnectedError) as e:
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 3
                    await asyncio.sleep(wait_time)
                    continue
                else:
                    raise Exception(f"API connection failed after {max_retries} retries: {type(e).__name__}")
            except Exception as e:
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 3
                    await asyncio.sleep(wait_time)
                    continue
                else:
                    raise Exception(f"Processing error after {max_retries} retries: {type(e).__name__}: {str(e)[:100]}")
        
        raise Exception("API request failed after all retries")


def flatten_analysis_results(analysis: Dict[str, Any]) -> Dict[str, Any]:
    """å°†åµŒå¥—çš„åˆ†æç»“æœå±•å¹³ä¸º DataFrame åˆ—"""
    flat = {}
    
    # Loss types
    for loss_type, data in analysis["loss_types"].items():
        flat[f"loss_{loss_type}_present"] = data["present"]
        flat[f"loss_{loss_type}_confidence"] = data["confidence"]
    
    # Urgency score
    flat["urgency_score"] = analysis["urgency_score_0_5"]
    
    # Visual cues
    flat["water_depth_bin"] = analysis["visual_cues"]["water_depth_bin"]
    flat["crowd_size_bin"] = analysis["visual_cues"]["crowd_size_bin"]
    flat["relief_visible"] = analysis["visual_cues"]["relief_visible"]
    flat["relief_actor_type"] = analysis["visual_cues"]["relief_actor_type"]
    flat["damage_signs"] = json.dumps(analysis["visual_cues"]["damage_signs"])
    
    # Demography
    for demo, present in analysis["demography_presence"].items():
        flat[f"demo_{demo}"] = present
    
    # Scene type
    for scene_key, present in analysis["scene_type"].items():
        flat[f"scene_{scene_key}"] = present
    
    # Context area (store as JSON string)
    flat["context_area"] = json.dumps(analysis["context_area"])
    
    # Sentiment
    for sent_item in analysis["sentiment"]:
        label = sent_item["label"]
        flat[f"sentiment_{label}_present"] = sent_item["present"]
        flat[f"sentiment_{label}_confidence"] = sent_item["confidence"]
    
    # Recovery
    flat["recovery_signals"] = analysis["recovery"]["recovery_signals"]
    flat["recovery_evidence"] = analysis["recovery"]["evidence"]
    
    return flat


async def process_csv_async(
    csv_path: str,
    output_csv_path: Optional[str] = None,
    platform: str = "tiktok",  # "tiktok" or "twitter"
    model: str = "qwen3-vl:32b-instruct",
    base_url: str = "http://127.0.0.1:11434",
    start_idx: int = 0,
    max_rows: Optional[int] = None,
    resume: bool = True,
    max_concurrent: int = 2
):
    """
    å¼‚æ­¥å¤„ç† CSV æ–‡ä»¶ï¼Œæ·»åŠ äººé“ä¸»ä¹‰å½±å“åˆ†æ
    """
    print(f"ğŸŒŠ Starting Humanitarian Impact Analysis ({platform.upper()} Mode)")
    print(f"âš¡ Max concurrent requests: {max_concurrent}")
    print("=" * 70)
    
    # è¯»å– CSV
    print(f"\nğŸ“– Reading CSV: {csv_path}")
    df = pd.read_csv(csv_path)
    print(f"âœ… Loaded {len(df)} rows")
    
    # ç¡®å®šè¾“å‡ºè·¯å¾„
    if output_csv_path is None:
        output_csv_path = csv_path
    
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    csv_path_obj = Path(csv_path).resolve()
    if csv_path_obj.parts[-3] == "csvs":
        project_root = csv_path_obj.parent.parent.parent.parent
    else:
        project_root = Path(csv_path).resolve()
        while project_root.parent != project_root:
            if any(p in ["tiktok", "twitter"] for p in project_root.parts):
                if project_root.name in ["tiktok", "twitter"]:
                    project_root = project_root.parent
                break
            project_root = project_root.parent
        if project_root == Path(csv_path).resolve():
            project_root = Path.cwd()
    
    # åˆå§‹åŒ–åˆ†ç±»å™¨
    analyzer = HumanitarianImpactAnalyzer(base_url=base_url, model=model)
    
    # è·å–æ‰€æœ‰éœ€è¦æ·»åŠ çš„åˆ—åï¼ˆä½¿ç”¨é»˜è®¤å“åº”ç»“æ„ï¼‰
    default_response = analyzer._get_default_response()
    flat_columns = flatten_analysis_results(default_response)
    
    # æ·»åŠ æ–°åˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    for col_name in flat_columns.keys():
        if col_name not in df.columns:
            df[col_name] = None
    
    # æ·»åŠ æ ‡è®°åˆ—ï¼Œè¡¨ç¤ºè¯¥è¡Œæ˜¯å¦å·²å®Œæˆåˆ†æ
    analysis_status_col = "humanitarian_analysis_complete"
    if analysis_status_col not in df.columns:
        df[analysis_status_col] = False
    
    # åˆ›å»ºå…¨å±€ aiohttp.ClientSession
    connector = aiohttp.TCPConnector(limit=max_concurrent * 2, limit_per_host=max_concurrent)
    timeout = aiohttp.ClientTimeout(total=600, connect=30)
    global_session = aiohttp.ClientSession(connector=connector, timeout=timeout)
    
    try:
        # ç¡®å®šå¤„ç†èŒƒå›´
        end_idx = len(df) if max_rows is None else min(start_idx + max_rows, len(df))
        rows_to_process = df.iloc[start_idx:end_idx]
        
        print(f"\nğŸ“Š Processing rows {start_idx} to {end_idx-1} (total: {len(rows_to_process)} rows)")
        print("-" * 70)
        
        # å‡†å¤‡ä»»åŠ¡åˆ—è¡¨
        tasks = []
        
        for idx, row in rows_to_process.iterrows():
            # æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡
            if resume and pd.notna(row.get(analysis_status_col)) and row.get(analysis_status_col):
                continue
            
            # æ ¹æ®å¹³å°æå–æ•°æ®
            if platform == "tiktok":
                title = row.get("title", "")
                hashtags = row.get("hashtags", "")
                transcription = row.get("transcription_english", "")
                
                # è§£æ key_frames
                key_frames_str = row.get("key_frames", "")
                image_paths = []
                
                if pd.notna(key_frames_str) and str(key_frames_str).strip():
                    try:
                        if isinstance(key_frames_str, str):
                            image_paths = json.loads(key_frames_str)
                        elif isinstance(key_frames_str, list):
                            image_paths = key_frames_str
                    except Exception:
                        pass
                
                if not image_paths and not title:
                    continue
                
                tasks.append((idx, "tiktok", title, hashtags, transcription, image_paths[:3]))
                
            elif platform == "twitter":
                text = row.get("text", "")
                
                # è§£æ all_images
                all_images_str = row.get("all_images", "")
                image_paths = []
                
                if pd.notna(all_images_str) and str(all_images_str).strip():
                    try:
                        if isinstance(all_images_str, str):
                            image_paths = json.loads(all_images_str)
                        elif isinstance(all_images_str, list):
                            image_paths = all_images_str
                    except Exception:
                        pass
                
                if not image_paths and not text:
                    continue
                
                # é™åˆ¶å›¾ç‰‡æ•°é‡ï¼šæœ€å¤š3å¼ 
                if len(image_paths) > 3:
                    image_paths_limited = random.sample(image_paths, 3)
                else:
                    image_paths_limited = image_paths
                
                tasks.append((idx, "twitter", text, image_paths_limited))
        
        if not tasks:
            print("âœ… All rows already processed or no tasks to process")
            return
        
        print(f"ğŸš€ Processing {len(tasks)} tasks with {max_concurrent} concurrent requests...")
        print("=" * 70)
        
        # é¢„çƒ­æ¨¡å‹ï¼Œå‡å°‘é¦–æ¬¡è°ƒç”¨å»¶è¿Ÿ
        try:
            print("ğŸ”¥ Warming up model (one-time request)...")
            await analyzer.warm_up(global_session)
        except Exception as warm_err:
            print(f"âš ï¸  Warm-up skipped due to error: {warm_err}")
        
        # åˆ›å»ºä¿¡å·é‡æ§åˆ¶å¹¶å‘
        semaphore = asyncio.Semaphore(max_concurrent)
        processed_count = asyncio.Lock()
        processed_num = [0]
        error_count = [0]
        session_lock = asyncio.Lock()
        
        async def process_single_task(task_data):
            """å¤„ç†å•ä¸ªä»»åŠ¡"""
            nonlocal global_session
            
            if task_data[1] == "tiktok":
                idx, _, title, hashtags, transcription, image_paths = task_data
            else:  # twitter
                idx, _, text, image_paths = task_data
            
            row_num = idx + 1
            
            async with semaphore:
                try:
                    # æ„å»º prompt
                    if task_data[1] == "tiktok":
                        user_prompt, images_base64 = analyzer._build_prompt_tiktok(
                            title=title,
                            hashtags=hashtags,
                            transcription=transcription,
                            image_paths=image_paths,
                            project_root=project_root
                        )
                    else:  # twitter
                        user_prompt, images_base64 = analyzer._build_prompt_twitter(
                            text=text,
                            image_paths=image_paths,
                            project_root=project_root
                        )
                    
                    # å‘é€è¯·æ±‚ï¼ˆå¸¦ session é‡å»ºæœºåˆ¶ï¼‰
                    attempt_result = None
                    for session_attempt in range(2):
                        try:
                            attempt_result = await analyzer._send_analysis_request(
                                user_prompt=user_prompt,
                                images_base64=images_base64,
                                session=global_session
                            )
                            break
                        except Exception as request_error:
                            error_message = str(request_error)
                            if session_attempt == 0 and "API connection failed" in error_message:
                                async with session_lock:
                                    await global_session.close()
                                    connector = aiohttp.TCPConnector(limit=max_concurrent * 2, limit_per_host=max_concurrent)
                                    timeout = aiohttp.ClientTimeout(total=600, connect=30)
                                    global_session = aiohttp.ClientSession(connector=connector, timeout=timeout)
                                await asyncio.sleep(1)
                                continue
                            raise
                    
                    if attempt_result is None:
                        raise Exception("Failed to obtain analysis result")
                    
                    # å±•å¹³ç»“æœå¹¶æ›´æ–° DataFrame
                    flat_result = flatten_analysis_results(attempt_result)
                    for col_name, value in flat_result.items():
                        df.at[idx, col_name] = value
                    df.at[idx, analysis_status_col] = True
                    
                    # æ›´æ–°è®¡æ•°
                    async with processed_count:
                        processed_num[0] += 1
                        current_count = processed_num[0]
                    
                    # æ‰“å°è¿›åº¦
                    urgency = flat_result.get("urgency_score", 0)
                    print(f"[{current_count}/{len(tasks)}] Row {row_num}: âœ… Analyzed (urgency: {urgency}/5)")
                    
                    # æ¯å¤„ç†5ä¸ªä»»åŠ¡ä¿å­˜ä¸€æ¬¡
                    if current_count % 5 == 0:
                        df.to_csv(output_csv_path, index=False)
                        print(f"ğŸ’¾ Progress saved: {current_count}/{len(tasks)} processed")
                    
                except Exception as e:
                    async with processed_count:
                        error_count[0] += 1
                        processed_num[0] += 1
                        current_count = processed_num[0]
                    
                    error_msg = str(e)[:100]
                    print(f"âŒ [{current_count}/{len(tasks)}] Row {row_num}: Failed - {error_msg}")
        
        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        await asyncio.gather(*[process_single_task(task) for task in tasks])
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        print(f"\nğŸ’¾ Saving final results to: {output_csv_path}")
        df.to_csv(output_csv_path, index=False)
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        print("\n" + "=" * 70)
        print("ğŸ“Š Summary:")
        print(f"   Total rows: {len(df)}")
        successful_count = processed_num[0] - error_count[0]
        print(f"   âœ… Successfully processed: {successful_count}")
        print(f"   â­ï¸  Skipped (already processed): {len(rows_to_process) - len(tasks)}")
        print(f"   âŒ Failed: {error_count[0]}")
        
        if error_count[0] > 0:
            print(f"\n   ğŸ’¡ Tip: Re-run the script to retry {error_count[0]} failed rows")
        
        print(f"   Output saved to: {output_csv_path}")
        print("=" * 70)
    
    finally:
        await global_session.close()


def process_csv(
    csv_path: str,
    output_csv_path: Optional[str] = None,
    platform: str = "tiktok",
    model: str = "qwen3-vl:32b-instruct",
    base_url: str = "http://127.0.0.1:11434",
    start_idx: int = 0,
    max_rows: Optional[int] = None,
    resume: bool = True,
    max_concurrent: int = 2
):
    """åŒæ­¥åŒ…è£…å‡½æ•°"""
    asyncio.run(process_csv_async(
        csv_path=csv_path,
        output_csv_path=output_csv_path,
        platform=platform,
        model=model,
        base_url=base_url,
        start_idx=start_idx,
        max_rows=max_rows,
        resume=resume,
        max_concurrent=max_concurrent
    ))


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="äººé“ä¸»ä¹‰å½±å“åˆ†æ - TikTok/Twitter æ´ªæ°´ç›¸å…³å¸–å­",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # TikTok æ•°æ®
  python humanitarian_impact_analysis.py tiktok/assam_flood/csvs/filtered_assam_flood_posts_20240501_20241120_with_local_paths.csv --platform tiktok
  
  # Twitter æ•°æ®
  python humanitarian_impact_analysis.py twitter/assam_flood/csvs/filtered_assam_flood_tweets_20240501_20240801_with_local_paths_20250721_172531.csv --platform twitter
  
  # æ‰¹é‡å¤„ç†ï¼ˆä½¿ç”¨ shell è„šæœ¬ï¼‰
  for file in tiktok/*/csvs/*.csv; do
    python humanitarian_impact_analysis.py "$file" --platform tiktok
  done
        """
    )
    
    parser.add_argument("csv_path", help="CSV æ–‡ä»¶è·¯å¾„")
    parser.add_argument("-o", "--output", help="è¾“å‡º CSV æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤è¦†ç›–åŸæ–‡ä»¶ï¼‰")
    parser.add_argument("--platform", choices=["tiktok", "twitter"], required=True, help="å¹³å°ç±»å‹")
    parser.add_argument("--model", default="qwen3-vl:32b", help="Ollama æ¨¡å‹åç§°")
    parser.add_argument("--base-url", default="http://127.0.0.1:11434", help="Ollama API URL")
    parser.add_argument("--start-idx", type=int, default=0, help="å¼€å§‹ç´¢å¼•")
    parser.add_argument("--max-rows", type=int, help="æœ€å¤§å¤„ç†è¡Œæ•°")
    parser.add_argument("--no-resume", action="store_true", help="ä¸ä½¿ç”¨æ–­ç‚¹ç»­ä¼ ")
    parser.add_argument("--max-concurrent", type=int, default=2, help="æœ€å¤§å¹¶å‘æ•°")
    
    args = parser.parse_args()
    
    if not os.path.exists(args.csv_path):
        print(f"âŒ CSV file not found: {args.csv_path}")
        return
    
    process_csv(
        csv_path=args.csv_path,
        output_csv_path=args.output,
        platform=args.platform,
        model=args.model,
        base_url=args.base_url,
        start_idx=args.start_idx,
        max_rows=args.max_rows,
        resume=not args.no_resume,
        max_concurrent=args.max_concurrent
    )
    
    print("\nğŸ‰ Analysis completed!")


if __name__ == "__main__":
    main()

